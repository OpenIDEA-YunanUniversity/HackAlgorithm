{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以信息增益为特征选择的决策树算法（ID3）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据\n",
    "数据来自西瓜书"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">     色泽,根蒂,敲声,纹理,脐部,触感,好瓜\n",
    "- 青绿,蜷缩,浊响,清晰,凹陷,硬滑,是\n",
    "- 乌黑,蜷缩,沉闷,清晰,凹陷,硬滑,是\n",
    "- 乌黑,蜷缩,浊响,清晰,凹陷,硬滑,是\n",
    "- 青绿,蜷缩,沉闷,清晰,凹陷,硬滑,是\n",
    "- 浅白,蜷缩,浊响,清晰,凹陷,硬滑,是\n",
    "- 青绿,稍蜷,浊响,清晰,稍凹,软粘,是\n",
    "- 乌黑,稍蜷,浊响,稍糊,稍凹,软粘,是\n",
    "- 乌黑,稍蜷,浊响,清晰,稍凹,硬滑,是\n",
    "- 乌黑,稍蜷,沉闷,稍糊,稍凹,硬滑,否\n",
    "- 青绿,硬挺,清脆,清晰,平坦,软粘,否\n",
    "- 浅白,硬挺,清脆,模糊,平坦,硬滑,否\n",
    "- 浅白,蜷缩,浊响,模糊,平坦,软粘,否\n",
    "- 青绿,稍蜷,浊响,稍糊,凹陷,硬滑,否\n",
    "- 浅白,稍蜷,沉闷,稍糊,凹陷,硬滑,否\n",
    "- 乌黑,稍蜷,浊响,清晰,稍凹,软粘,否\n",
    "- 浅白,蜷缩,浊响,模糊,平坦,硬滑,否\n",
    "- 青绿,蜷缩,沉闷,稍糊,稍凹,硬滑,否\n",
    "\n",
    "1. 色泽>青绿:1, 乌黑:2, 浅白:3 \n",
    "2. 根蒂>蜷缩:1, 稍蜷:2, 硬挺:3\n",
    "3. 敲声>浊响:1,沉闷:2,清脆:3\n",
    "4. 纹理>清晰:1，稍糊:2, 模糊:3\n",
    "5. 脐部>凹陷:1,稍凹:2,平坦:3\n",
    "6. 触感>硬滑:1,软粘:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chn_data = [['青绿','蜷缩','浊响','清晰','凹陷','硬滑','是'],\n",
    "['乌黑','蜷缩','沉闷','清晰','凹陷','硬滑','是'],\n",
    "['乌黑','蜷缩','浊响','清晰','凹陷','硬滑','是'],\n",
    "['青绿','蜷缩','沉闷','清晰','凹陷','硬滑','是'],\n",
    "['浅白','蜷缩','浊响','清晰','凹陷','硬滑','是'],\n",
    "['青绿','稍蜷','浊响','清晰','稍凹','软粘','是'],\n",
    "['乌黑','稍蜷','浊响','稍糊','稍凹','软粘','是'],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','硬滑','是'],\n",
    "['乌黑','稍蜷','沉闷','稍糊','稍凹','硬滑','否'],\n",
    "['青绿','硬挺','清脆','清晰','平坦','软粘','否'],\n",
    "['浅白','硬挺','清脆','模糊','平坦','硬滑','否'],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','软粘','否'],\n",
    "['青绿','稍蜷','浊响','稍糊','凹陷','硬滑','否'],\n",
    "['浅白','稍蜷','沉闷','稍糊','凹陷','硬滑','否'],\n",
    "['乌黑','稍蜷','浊响','清晰','稍凹','软粘','否'],\n",
    "['浅白','蜷缩','浊响','模糊','平坦','硬滑','否'],\n",
    "['青绿','蜷缩','沉闷','稍糊','稍凹','硬滑','否']]\n",
    "\n",
    "hash_dict =  {'青绿':1,'乌黑':2, '浅白':3, \n",
    "            '蜷缩':1, '稍蜷':2, '硬挺':3,\n",
    "            '浊响':1,'沉闷':2,'清脆':3,\n",
    "            '清晰':1,'稍糊':2, '模糊':3,\n",
    "            '凹陷':1,'稍凹':2,'平坦':3,\n",
    "            '硬滑':1,'软粘':2,\n",
    "              '是':1,'否':0\n",
    "             }\n",
    "\n",
    "train = []\n",
    "for row_vec in chn_data:\n",
    "    tmp = []\n",
    "    for col in row_vec:\n",
    "        tmp.append(hash_dict[col])\n",
    "    train.append(tmp)\n",
    "\n",
    "feature_map = {0:'色泽',1:'根蒂',2:'敲声',3:'纹理',4:'脐部',5:'触感'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = np.array(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法推导 （ID3）\n",
    "### Descision Tree through ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "熵(entropy) 定义为：\n",
    "$$P(X=x_i)=P_i, i\\in{1,2,3...n},其中 1,2,3...为特征X_i的取值$$\n",
    "\n",
    "随机变量X的熵定义为（表示这个随机变量的不确定性）\n",
    "$$H(x)=-\\sum_{i=1}^n{P_i*log{P_i}}$$\n",
    "\n",
    "熵只依赖于$X$的分布,而与X的取值无关，so，可以写成\n",
    "$$H(p)=-\\sum_{i=1}^n{P_i*log{P_i}}$$\n",
    "\n",
    "显然，熵值越大，随机变量(特征)的不确定性就越大，当然，在整个数据集中，单独看一个特征的熵是没有意义的，整个训练必定有标签$y$,那么就有$X,Y$的联合概率分布为：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(vector):\n",
    "    \"\"\"\n",
    "    vector just contain the lables, 1D aray like so\n",
    "    \"\"\"\n",
    "    elements = np.unique(vector)\n",
    "    entropy = 0.0\n",
    "    vec_size = vector.shape[0]\n",
    "    \n",
    "    for unique_val in elements:\n",
    "        prob = list(vector).count(unique_val)/vec_size+0.0\n",
    "        entropy -= prob*np.log2(prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(complete_data, feature_idx, val):\n",
    "    \"\"\"\n",
    "    split the original data through feature index and its value\n",
    "    then reurn the subset within label\n",
    "    \"\"\"\n",
    "    subset = np.c_[complete_data[:,feature_idx], complete_data[:,-1]]\n",
    "    subset_target = np.where(subset[:,0]==val)\n",
    "    subset = complete_data[subset_target,:]\n",
    "    subset = subset[0]\n",
    "    return np.delete(subset, feature_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def info_gain(dataset, feature_idx):\n",
    "    \"\"\"\n",
    "    calculate the appointed features's informathon gain while the dataset\n",
    "    should store all the label, definitely.Otherwise,the programe will be wrong\n",
    "    \"\"\"\n",
    "    base_entropy = calculate_entropy(dataset[:,-1])\n",
    "    empircal_condition_entropy = 0.0\n",
    "    \n",
    "    for feature_val in np.unique(dataset[:, feature_idx]):\n",
    "        subset = split_data(dataset, feature_idx, feature_val)\n",
    "        current_entropy = calculate_entropy(subset[:,-1])\n",
    "        empircal_condition_entropy += (subset.shape[0]/dataset.shape[0]+0.0)*current_entropy\n",
    "    \n",
    "    return base_entropy-empircal_condition_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chose_best_feature(dataset):\n",
    "    maximum_infor_gain = 0.0\n",
    "    best_feature_idx = -1\n",
    "    \n",
    "    for feature_idx in range(dataset.shape[1]-1):\n",
    "        this_infor_gain = info_gain(dataset, feature_idx)\n",
    "        if this_infor_gain>maximum_infor_gain:\n",
    "            best_feature_idx = feature_idx\n",
    "            maximum_infor_gain = this_infor_gain\n",
    "    \n",
    "    return best_feature_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vote(classlist):\n",
    "    return classlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_tree(train, feature_vec):\n",
    "    \n",
    "    classlist = list(train[:,-1])\n",
    "    if classlist.count(classlist[0]) == len(classlist):\n",
    "        return classlist[0]\n",
    "    if train.shape[0]==1:\n",
    "        \n",
    "        return vote(classlist)\n",
    "    \n",
    "    best_feature_idx = chose_best_feature(train)\n",
    "    best_feature_name = feature_vec[best_feature_idx]\n",
    "    tree = {best_feature_name:{}}\n",
    "\n",
    "    del(feature_vec[best_feature_idx])\n",
    "    \n",
    "    for feature_val in np.unique(train[:,best_feature_idx]):\n",
    "        sub_feature_vec = feature_vec[:]\n",
    "        tree[best_feature_name][feature_val] = build_tree(split_data(train, best_feature_idx, feature_val), sub_feature_vec)\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'纹理': {1: {'根蒂': {1: 1, 2: {'色泽': {1: 1, 2: {'触感': {1: 1, 2: 0}}}}, 3: 0}},\n",
       "  2: {'触感': {1: 0, 2: 1}},\n",
       "  3: 0}}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vec = ['色泽','根蒂','敲声','纹理','脐部','触感']\n",
    "build_tree(train, feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
